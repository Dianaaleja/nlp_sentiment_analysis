{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77638988",
   "metadata": {},
   "source": [
    "## 1. Install libraries needed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b20b4862",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/dianaterraza/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/dianaterraza/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/dianaterraza/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dianaterraza/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np  # for numerical operations\n",
    "import pandas as pd  # for data manipulation\n",
    "import random  # for shuffling the data\n",
    "import nltk\n",
    "import re  # for handling regular expressions\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer  # for lemmatizing words\n",
    "from nltk.corpus import stopwords  # for stop word removal\n",
    "from nltk.tokenize import word_tokenize  # for tokenizing sentences into words\n",
    "nltk.download('punkt_tab')  # Downloads the 'punkt' tokenizer table used for tokenization of text into sentences or words\n",
    "from nltk import bigrams  # For generating bigrams\n",
    "\n",
    "# Downloading necessary NLTK resources\n",
    "nltk.download('stopwords')  # List of common stop words in English\n",
    "nltk.download('punkt')  # Pre-trained tokenizer models\n",
    "nltk.download('wordnet')  # WordNet lemmatizer dataset\n",
    "\n",
    "# Libraries for text feature extraction and model training\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # Convert text into numerical features (TF-IDF)\n",
    "from sklearn.linear_model import LogisticRegression  # Logistic regression for classification\n",
    "from sklearn.model_selection import GridSearchCV  # For hyperparameter tuning\n",
    "from sklearn.svm import LinearSVC  # Support Vector Machines for classification\n",
    "\n",
    "# Libraries for model evaluation\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix  # For model evaluation metrics\n",
    "from sklearn.model_selection import KFold, cross_val_score  # For cross-validation\n",
    "from sklearn.model_selection import train_test_split # For splitting the dataset into training and testing sets\n",
    "from sklearn.metrics import classification_report, accuracy_score  # For evaluating the model's performance\n",
    "\n",
    "from collections import Counter  # For counting word frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9299d9e4",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d36e2e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/dianaterraza/Desktop/nlp_project/data/Restaurant_Reviews.tsv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "21fef368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our server was fantastic and when he found out the wife loves roasted garlic and bone marrow, he added extra to our meal and another marrow to go!\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[100]['Review'])  # Display the review at index 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1afa8c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[122]['Liked']  # Display the sentiment label for the review at index 120"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50481e28",
   "metadata": {},
   "source": [
    "Liked – A binary target variable:\n",
    "* 1: The customer liked the food.\n",
    "* 0: The customer did not like the food.\n",
    "\n",
    "### Count how many of every category we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dfc89b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Liked\n",
       "1    500\n",
       "0    500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Liked'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8875d6",
   "metadata": {},
   "source": [
    "### Look for null values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6cc40020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review    0\n",
       "Liked     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06246fbb",
   "metadata": {},
   "source": [
    "### Visualize the positive and negatives numbers: (1) Liked the food, (0) didnt liked the food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "53761d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjUsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvWftoOwAAAAlwSFlzAAAPYQAAD2EBqD+naQAANdFJREFUeJzt3QeYFFW+/vEfzJBhSMIASlKRoAQXWIKRrKLCghkRFcNFQIQVcVYkKyyrICouuquAAVFcw4qIEswEERckX/GqoMCAIgyoQ+z/8557q//dw8wwwMx0c+b7eZ6i6arq6lM1Hd4+oapQKBQKGQAAgKcKx7oAAAAAeYmwAwAAvEbYAQAAXiPsAAAArxF2AACA1wg7AADAa4QdAADgNcIOAADwGmEHAAB4jbADmNmIESOsUKFC+fJcF198sZsCH374oXvu1157LV+e/+abb7ZatWpZPNu7d6/ddtttVqVKFXds7rnnHjuZfPfdd67c06ZNi3VR4v4999NPPxWo1zZig7AD7+gLRh+iwVS8eHGrVq2aderUyR5//HHbs2dPrjzPli1b3Af2ihUrLN7Ec9ly4uGHH3Z/xz59+tgLL7xgPXv2zHLd/fv326RJk+zcc8+1pKQkK1eunJ199tl2xx132Pr16/O0nDNmzLDHHnvMTlZz5sxxr5OcUkg/55xz8rRMQF5IzJOtAnFg1KhRVrt2bTtw4IBt27bN1aCohmDChAn273//2xo1ahRed+jQoXb//fcfc6AYOXKk+yXZpEmTHD/u/ffft7yWXdn+8Y9/2OHDhy2eLVy40Fq2bGnDhw8/6rrdu3e3d999166//nq7/fbb3d9bIWf27NnWunVrq1evXp6GndWrVx9R81SzZk37/fffrUiRIhbvYWfy5MnHFHiAkxFhB9669NJLrVmzZuH7KSkp7kv08ssvtyuvvNLWrVtnJUqUcMsSExPdlJd+++03K1mypBUtWtRiKd6/gGX79u3WoEGDo663bNkyF2oeeugh+8tf/hK17Mknn7Rdu3ZZLAQ1igDiA81YKFDatm1rDz74oH3//ff24osvZttnZ968eXb++ee7ZpHSpUtb3bp1w1+oqiVq3ry5+/8tt9wSbjIL+mgE1f3Lly+3Cy+80IWc4LEZ++wEDh065NZRP5VSpUq5QLZ58+aodVRTo34JGUVu82hly6xfw6+//mp//vOfrXr16lasWDG3r4888oiFQqGo9bSdfv362Ztvvun2T+uqyWju3Lk5DjG9e/e25ORkFwYaN25s06dPP6L/0rfffmvvvPNOuOzqA5OZb775xt2ed955RyxLSEiwihUrRs378ccf7dZbb3XPH5T9ueeei1onKMOrr77qQtRpp53mytquXTvbuHFj1DFXGfVaCsoZHNfM+uzouOt1tGnTJhe49f9TTz3V1azIqlWr3OtTf3vVDKnWKCOFN9UiBX+nM8880/76179G1dQFz62/3zPPPGNnnHGGW1evCYXDyPIEzx3Z7HuivvrqK7ft008/3R03vZ51zH/++edM11efnWuuucY1QervNWDAAEtPTz9iPb1fmzZt6n6gVKhQwa677roj3h+ZmTlzpntcmTJl3HM0bNjQNXuiYKFmBwWO+n8oVKg5Sc0emVmzZo37QlJTl5rD9GWhL7rPPvvMLa9fv76bP2zYMNc35IILLnDz1WwS0Ie7apf0oXzjjTe6L9js6ItVXzZDhgxxoUB9Qdq3b+/63QQ1UDmRk7JFUqBRsPrggw9cEFGz13vvvWeDBw924WDixIlR63/66af2+uuv21133eW+QNQPSk1J+hLPGC4iqVlHAUHHUYFJTYyzZs1yX4z6EteXnMquPjoDBw50IUMBTCpVqpTpNhUK5KWXXnKBJ7vaudTUVNc0FgQ2bVPNX9rntLS0I5qixo0bZ4ULF7Z7773Xdu/ebePHj7cePXrY0qVL3fIHHnjAzf/hhx/Cx0gBJjsKtHpNKABreyq3yqKAo+1p+926dbMpU6bYTTfdZK1atXLHKagZvOiii9zf5M4777QaNWrYokWLXI3l1q1bj+g7pLCk/mlaV/us59O2/+d//sfV7mm+mjsV6nXMc4u2p+dQ0FbQ0XtJoUu3S5YsOSJQKegoJI4dO9Yt1+vpl19+seeffz7qvaEfKVpXHdd37NhhTzzxhDuO//nPf9wPkqzKouZNBVWFQlGNrt7Her2hAAkBnpk6daqqI0LLli3Lcp2yZcuGzj333PD94cOHu8cEJk6c6O7v2LEjy21o+1pHz5fRRRdd5JZNmTIl02WaAh988IFb99RTTw2lpaWF57/66qtu/qRJk8LzatasGerVq9dRt5ld2fR4bSfw5ptvunXHjBkTtd5VV10VKlSoUGjjxo3heVqvaNGiUfNWrlzp5j/xxBOh7Dz22GNuvRdffDE8b//+/aFWrVqFSpcuHbXvKl/nzp1DR3P48OHwsU5OTg5df/31ocmTJ4e+//77I9bt3bt3qGrVqqGffvopav51113nXg+//fZb1N+jfv36oX379oXX099B81etWhWepzJGHsvAt99+e8Tx13HXvIcffjg875dffgmVKFHCHeeZM2eG569fv96tq9dlYPTo0aFSpUqF/vu//zvque6///5QQkJCaNOmTVHPXbFixdDOnTvD67311ltu/ttvvx2e17dv36jX/dHoWJ999tnZrhMcx0gvv/yye56PP/74iPfclVdeGbXuXXfd5ebrdSXfffed27+HHnooaj39HRITE6PmZ3xtDxgwIJSUlBQ6ePBgjvcRfqIZCwWSfoFnNyor+KX41ltvHXdnXtUG6ddtTumXvGpKAldddZVVrVrVdSLNS9q+mnzuvvvuqPmqVVG+Ue1HJNU2qWkkoNovNQ/o1/zRnke/9PVLO6AaBj2vhpp/9NFHx1x21RKoFmrMmDFWvnx5e/nll61v376uxufaa68N99nRfvzrX/+yK664wv1fTSfBpFF6qqH58ssvo7atv11k/6qghuxo+3k0qpmIfJ2pyVA1O6q1CGielkU+l2rBVAbtZ2T59fdQjdHHH38c9Tzaf62b2+U/mshaSDVHqYyqUZOMx1j094rUv39/dxu87lWLqPegjk/kfuu1VKdOHVcjmRUdQzXRqoYHBRthBwWSvlwjg0VG+qJQs4i+mNT8pKYo9eE4luCj/hjH0hlZH9wZv8jVJyOr/iq5RX1ONDQ/4/FQk1KwPJKaTzLSl6qaHo72PNpHNQ3l5HmOJVSqCUjNE2qWUeDRl6v+XmoiEjV7KPioOUXNV5FTEEjVdJjdfgbB4Wj7mR31YcnYJFe2bFnXZJexeUfzI5/r66+/dn2jMpZfYSe/yp8TO3fudE1Eet8o+KiMQVOcQuXRXvcK0nqNBK977bcCqtbLuO/6m2fc70hqaj3rrLNc06GOsfoO5bR/GfxCnx0UOOpjoQ9dBYms6ENav5T1q1GdUPUB+corr7gOpOrro5qQozmWfjY5lVUHUv2yz0mZckNWz5OxM3MsqCZMwVR9iNT5WIFHnYSDkKq+U7169cr0sZGnIsir/cxqmzl5Lu1Dhw4d7L777st0XX2pH+s284JqYNSXSH2+1P9Ltagq+yWXXJKjHwsZX+N6jOaphjGzfcqun1TlypVdnzfV/unxmqZOnepqUSM7xsN/hB0UOEFnTDVfZEe/LtWxUZPOzaMT3akGQQFIv6Zz+4zL+gWb8UtJnXkjv4T16zyz4dSqFdHol8CxlE1NPvPnz3fNepG1O8EJ+YJOwCdK29FIHX15Rdbu5PbzBM1jOm46pmryUC2A9k2hMKgJyQ35ddbtoMZDNZLxXH7VGi1YsMCd40kd5LN6bUfSsqDmR/Sa12skGNmm/dZ7QetkDHQ5odpVNV9q0nZV2/P000+7Ds/Z/eCBX2jGQoGi8+yMHj3afXBq5Et2VfEZBSfn27dvn7tVPwvJrXO5aPRJZD8iXT5Co2xUBR/QB79GrOiswQGdZybjENxjKdtll13mQoDOSxNJI4z0ZRj5/CdCz6OTO6qGLHDw4EE3qka/zjXS6Fjpi1KjwDLSfi9evNiFQwUd1Qiotkf9dnQSwIzUzHU8dJwza5rJqxoT7ZNqKTLbXx3LY5Xbr+Gg5iVj7VF2Z5kOhr8H9HqQ4HWnEWTargJUxu3qflZD2iXjMoXs4MdD8D5GwUDNDrylKmvVGuhLQMOOFXTUUVE1CDqDcnYnfdPQbTVjde7c2a2vfgFPPfWUa/fXuXeC4KEOkBomrFoDfXG0aNEi6lfqsdC5Q7Rt9SFRefUFoV+ekcPj1YdIIUhNAvry03lmdP6RyA7Dx1o2/eJt06aNq7VSPwmd+0ZNdeqcreHYGbd9vDQMXr+oNdRc5x/SL3fti4YBa1+z60OVlZUrV9oNN9zgvhjVAVfHUEOz1USh/jvabvAFrKHkqpXTcdAx1UkLFWrVaVY1W5kF3KPR+VsU3gYNGuTOY6PQpuOZF9QspNetTomgY6jnVudbnZ9Hx1F/u1NOOeWYyy/qJK6aTh0rNQNmR8FQHcIzCn5ABMPqdSZr9VvTa0nnTcqKlunUB3pNK8zp9ay/qV6Hotefnk9D7LWPXbt2da8VPe6NN95wryudHiAzer/o76rmZ713VQOqMKUfLkFfMRQQsR4OBuTV0PNg0lDpKlWqhDp06OCGD0cOcc5q6PmCBQtCXbp0CVWrVs09Xrca1pxx2K+G8zZo0MANgY0capzdEN2shp5reG5KSkqocuXKbjiyhjVnNoT60UcfdcPUixUrFjrvvPNCX3zxxRHbzK5sGYfnyp49e0IDBw50+1mkSJFQnTp1Qn/729/c0O5I2o6GK2eU1ZD4jFJTU0O33HJL6JRTTnHHtWHDhpkOj8/p0HNtb9y4cW7fNaxc+1q+fPlQ27ZtQ6+99lqm66v81atXd/up10W7du1CzzzzzBF/j1mzZh11OPnevXtDN9xwQ6hcuXJuWXBcsxp6rqHjGWX1WsnsGOjvpNfImWee6Y6fjmPr1q1DjzzyiBvGH/nc+vtllHE4u4Zk9+/fP1SpUiU3/P1oXwnBMP/MJh1H+eGHH0J/+tOf3DHRkP6rr746tGXLliOeO3jPrV271p3moEyZMu5v169fv9Dvv/9+xHP/61//Cp1//vnuGGqqV6+e+1tu2LAh6hhHvrb1GujYsaN7T+l41ahRI3TnnXeGtm7dmu1+wj+F9E+sAxcAAEBeoc8OAADwGmEHAAB4jbADAAC8RtgBAABeI+wAAACvEXYAAIDXOKng/117RScg04mq8vP07wAA4Pjp7Dk687wuZpzxIsORCDtmLuhUr1491sUAAADHQZfM0Vmys0LYMQufpl4HKykpKdbFAQAAOZCWluYqK452uRnCTsSVfxV0CDsAAJxcjtYFhQ7KAADAa4QdAADgNcIOAADwGmEHAAB4jbADAAC8RtgBAABeI+wAAACvEXYAAIDXCDsAAMBrhB0AAOC1mIadESNGuFM8R0716tULL09PT7e+fftaxYoVrXTp0ta9e3dLTU2N2samTZusc+fOVrJkSatcubINHjzYDh48GIO9AQAA8Sjm18Y6++yzbf78+eH7iYn/v0gDBw60d955x2bNmmVly5a1fv36Wbdu3eyzzz5zyw8dOuSCTpUqVWzRokW2detWu+mmm6xIkSL28MMPx2R/AABAfIl52FG4UVjJaPfu3fbss8/ajBkzrG3btm7e1KlTrX79+rZkyRJr2bKlvf/++7Z27VoXlpKTk61JkyY2evRoGzJkiKs1Klq0aAz2CAAAxJOY99n5+uuvrVq1anb66adbjx49XLOULF++3A4cOGDt27cPr6smrho1atjixYvdfd02bNjQBZ1Ap06d3CXf16xZE4O9AQAA8SamNTstWrSwadOmWd26dV0T1MiRI+2CCy6w1atX27Zt21zNTLly5aIeo2CjZaLbyKATLA+WZWXfvn1uCigcAQAAP8U07Fx66aXh/zdq1MiFn5o1a9qrr75qJUqUyLPnHTt2rAtWMNvNcShQyg4fHusiIB9N+mVSrIuAfDSg/IBYFyFuxbwZK5Jqcc466yzbuHGj68ezf/9+27VrV9Q6Go0V9PHRbcbRWcH9zPoBBVJSUlyfoGDavHlznuwPAACIvbgKO3v37rVvvvnGqlatak2bNnWjqhYsWBBevmHDBtenp1WrVu6+bletWmXbt28PrzNv3jxLSkqyBg0aZPk8xYoVc+tETgAAwE8xbca699577YorrnBNV1u2bLHhw4dbQkKCXX/99W6oee/evW3QoEFWoUIFF0j69+/vAo5GYknHjh1dqOnZs6eNHz/e9dMZOnSoOzePAg0AAEBMw84PP/zggs3PP/9slSpVsvPPP98NK9f/ZeLEiVa4cGF3MkF1KNZIq6eeeir8eAWj2bNnW58+fVwIKlWqlPXq1ctGjRoVw70CAADxJKZhZ+bMmdkuL168uE2ePNlNWVGt0Jw5c/KgdAAAwAdx1WcHAAAgtxF2AACA1wg7AADAa4QdAADgNcIOAADwGmEHAAB4jbADAAC8RtgBAABeI+wAAACvEXYAAIDXCDsAAMBrhB0AAOA1wg4AAPAaYQcAAHiNsAMAALxG2AEAAF4j7AAAAK8RdgAAgNcIOwAAwGuEHQAA4DXCDgAA8BphBwAAeI2wAwAAvEbYAQAAXiPsAAAArxF2AACA1wg7AADAa4QdAADgNcIOAADwGmEHAAB4jbADAAC8RtgBAABeI+wAAACvEXYAAIDXCDsAAMBrhB0AAOA1wg4AAPAaYQcAAHiNsAMAALxG2AEAAF4j7AAAAK8RdgAAgNcIOwAAwGuEHQAA4DXCDgAA8BphBwAAeI2wAwAAvEbYAQAAXiPsAAAArxF2AACA1wg7AADAa4QdAADgNcIOAADwGmEHAAB4jbADAAC8RtgBAABeI+wAAACvEXYAAIDXCDsAAMBrhB0AAOC1uAk748aNs0KFCtk999wTnpeenm59+/a1ihUrWunSpa179+6Wmpoa9bhNmzZZ586drWTJkla5cmUbPHiwHTx4MAZ7AAAA4lFchJ1ly5bZ008/bY0aNYqaP3DgQHv77bdt1qxZ9tFHH9mWLVusW7du4eWHDh1yQWf//v22aNEimz59uk2bNs2GDRsWg70AAADxKOZhZ+/evdajRw/7xz/+YeXLlw/P3717tz377LM2YcIEa9u2rTVt2tSmTp3qQs2SJUvcOu+//76tXbvWXnzxRWvSpIldeumlNnr0aJs8ebILQAAAADEPO2qmUu1M+/bto+YvX77cDhw4EDW/Xr16VqNGDVu8eLG7r9uGDRtacnJyeJ1OnTpZWlqarVmzJsvn3Ldvn1sncgIAAH5KjOWTz5w507788kvXjJXRtm3brGjRolauXLmo+Qo2WhasExl0guXBsqyMHTvWRo4cmUt7AQAA4lnManY2b95sAwYMsJdeesmKFy+er8+dkpLimsmCSWUBAAB+ilnYUTPV9u3b7Q9/+IMlJia6SZ2QH3/8cfd/1dCo382uXbuiHqfRWFWqVHH/123G0VnB/WCdzBQrVsySkpKiJgAA4KeYhZ127drZqlWrbMWKFeGpWbNmrrNy8P8iRYrYggULwo/ZsGGDG2reqlUrd1+32oZCU2DevHkuvDRo0CAm+wUAAOJLzPrslClTxs4555yoeaVKlXLn1Anm9+7d2wYNGmQVKlRwAaZ///4u4LRs2dIt79ixows1PXv2tPHjx7t+OkOHDnWdnlV7AwAAENMOykczceJEK1y4sDuZoEZQaaTVU089FV6ekJBgs2fPtj59+rgQpLDUq1cvGzVqVEzLDQAA4kdchZ0PP/ww6r46LuucOZqyUrNmTZszZ04+lA4AAJyMYn6eHQAAgLxE2AEAAF4j7AAAAK8RdgAAgNcIOwAAwGuEHQAA4DXCDgAA8BphBwAAeI2wAwAAvEbYAQAAXiPsAAAArxF2AACA1wg7AADAa4QdAADgNcIOAADwGmEHAAB4jbADAAC8RtgBAABeI+wAAACvEXYAAIDXCDsAAMBrhB0AAOA1wg4AAPAaYQcAAHiNsAMAALxG2AEAAF4j7AAAAK8RdgAAgNcIOwAAwGuEHQAA4DXCDgAA8BphBwAAeI2wAwAAvEbYAQAAXiPsAAAArxF2AACA1wg7AADAa4QdAADgNcIOAADwGmEHAAB4jbADAAC8RtgBAABeI+wAAACvEXYAAIDXCDsAAMBrhB0AAOA1wg4AAPAaYQcAAHiNsAMAALxG2AEAAF4j7AAAAK8RdgAAgNcIOwAAwGuEHQAA4DXCDgAA8BphBwAAeI2wAwAAvEbYAQAAXiPsAAAAr8U07Pz973+3Ro0aWVJSkptatWpl7777bnh5enq69e3b1ypWrGilS5e27t27W2pqatQ2Nm3aZJ07d7aSJUta5cqVbfDgwXbw4MEY7A0AAIhHMQ07p512mo0bN86WL19uX3zxhbVt29a6dOlia9asccsHDhxob7/9ts2aNcs++ugj27Jli3Xr1i38+EOHDrmgs3//flu0aJFNnz7dpk2bZsOGDYvhXgEAgHhSKBQKhSyOVKhQwf72t7/ZVVddZZUqVbIZM2a4/8v69eutfv36tnjxYmvZsqWrBbr88stdCEpOTnbrTJkyxYYMGWI7duywokWL5ug509LSrGzZsrZ7925Xw1SQ7B45MtZFQD4qO3x4rIuAfDTpl0mxLgLy0YDyA6ygScvh93fc9NlRLc3MmTPt119/dc1Zqu05cOCAtW/fPrxOvXr1rEaNGi7siG4bNmwYDjrSqVMnt/NB7RAAACjYEmNdgFWrVrlwo/456pfzxhtvWIMGDWzFihWuZqZcuXJR6yvYbNu2zf1ft5FBJ1geLMvKvn373BRQOAIAAH6Kec1O3bp1XbBZunSp9enTx3r16mVr167N0+ccO3asq/YKpurVq+fp8wEAgAIcdlR7c+aZZ1rTpk1dCGncuLFNmjTJqlSp4joe79q1K2p9jcbSMtFtxtFZwf1gncykpKS49r1g2rx5c57sGwAAiL2Yh52MDh8+7JqYFH6KFCliCxYsCC/bsGGDG2quZi/RrZrBtm/fHl5n3rx5rpOSmsKyUqxYsfBw92ACAAB+immfHdWwXHrppa7T8Z49e9zIqw8//NDee+8917zUu3dvGzRokBuhpUDSv39/F3A0Eks6duzoQk3Pnj1t/Pjxrp/O0KFD3bl5FGgAAABiGnZUI3PTTTfZ1q1bXbjRCQYVdDp06OCWT5w40QoXLuxOJqjaHo20euqpp8KPT0hIsNmzZ7u+PgpBpUqVcn1+Ro0aFcO9AgAA8SSmYefZZ5/Ndnnx4sVt8uTJbspKzZo1bc6cOXlQOgAA4IO467MDAACQmwg7AADAa8cVdk4//XT7+eefj5ivYeJaBgAAcFKHne+++85d3iEjdSL+8ccfc6NcAAAA+d9B+d///nf4/8Hw8IDCj86JU6tWrdwpGQAAQH6Hna5du7rbQoUKuSHekXQCQAWdRx99NDfKBQAAkP9hR2c3ltq1a9uyZcvslFNOyZ1SAAAAxNN5dr799tvcLwkAAEA8nVRQ/XM06SzIQY1P4LnnnsuNsgEAAMQm7IwcOdJdkqFZs2ZWtWpV14cHAADAm7AzZcoUmzZtmrsAJwAAgHfn2dm/f7+1bt0690sDAAAQD2HntttusxkzZuR2WQAAAOKjGSs9Pd2eeeYZmz9/vjVq1MidYyfShAkTcqt8AAAA+R92vvrqK2vSpIn7/+rVq6OW0VkZAACc9GHngw8+yP2SAAAAxEufHQAAAK9rdtq0aZNtc9XChQtPpEwAAAC55rjCTtBfJ3DgwAFbsWKF67+T8QKhAAAAJ13YmThxYqbzR4wYYXv37j3RMgEAAMRnn50bb7yR62IBAAB/w87ixYutePHiublJAACA/G/G6tatW9T9UChkW7dutS+++MIefPDBEysRAABArMNO2bJlo+4XLlzY6tat666E3rFjx9wqGwAAQGzCztSpU0/8mQEAAOI17ASWL19u69atc/8/++yz7dxzz82tcgEAAMQu7Gzfvt2uu+46+/DDD61cuXJu3q5du9zJBmfOnGmVKlXKndIBAADEYjRW//79bc+ePbZmzRrbuXOnm3RCwbS0NLv77rtPtEwAAACxrdmZO3euzZ8/3+rXrx+e16BBA5s8eTIdlAEAwMlfs3P48GErUqTIEfM1T8sAAABO6rDTtm1bGzBggG3ZsiU878cff7SBAwdau3btcrN8AAAA+R92nnzySdc/p1atWnbGGWe4qXbt2m7eE088cWIlAgAAiHWfnerVq9uXX37p+u2sX7/ezVP/nfbt2+dm2QAAAPK3ZmfhwoWuI7JqcAoVKmQdOnRwI7M0NW/e3J1r55NPPjnxUgEAAMQi7Dz22GN2++23W1JSUqaXkLjzzjttwoQJuVU2AACA/A07K1eutEsuuSTL5Rp2rrMqAwAAnJRhJzU1NdMh54HExETbsWNHbpQLAAAg/8POqaee6s6UnJWvvvrKqlatmhvlAgAAyP+wc9lll9mDDz5o6enpRyz7/fffbfjw4Xb55ZfnTskAAADye+j50KFD7fXXX7ezzjrL+vXrZ3Xr1nXzNfxcl4o4dOiQPfDAA7lRLgAAgPwPO8nJybZo0SLr06ePpaSkWCgUcvM1DL1Tp04u8GgdAACAk/akgjVr1rQ5c+bYL7/8Yhs3bnSBp06dOla+fPm8KSEAAEB+n0FZFG50IkEAAADvro0FAABwsiDsAAAArxF2AACA1wg7AADAa4QdAADgNcIOAADwGmEHAAB4jbADAAC8RtgBAABeI+wAAACvEXYAAIDXCDsAAMBrhB0AAOA1wg4AAPAaYQcAAHiNsAMAALxG2AEAAF6LadgZO3asNW/e3MqUKWOVK1e2rl272oYNG6LWSU9Pt759+1rFihWtdOnS1r17d0tNTY1aZ9OmTda5c2crWbKk287gwYPt4MGD+bw3AAAgHsU07Hz00UcuyCxZssTmzZtnBw4csI4dO9qvv/4aXmfgwIH29ttv26xZs9z6W7ZssW7duoWXHzp0yAWd/fv326JFi2z69Ok2bdo0GzZsWIz2CgAAxJPEWD753Llzo+4rpKhmZvny5XbhhRfa7t277dlnn7UZM2ZY27Zt3TpTp061+vXru4DUsmVLe//9923t2rU2f/58S05OtiZNmtjo0aNtyJAhNmLECCtatGiM9g4AAMSDuOqzo3AjFSpUcLcKPartad++fXidevXqWY0aNWzx4sXuvm4bNmzogk6gU6dOlpaWZmvWrMn0efbt2+eWR04AAMBPcRN2Dh8+bPfcc4+dd955ds4557h527ZtczUz5cqVi1pXwUbLgnUig06wPFiWVV+hsmXLhqfq1avn0V4BAIBYi5uwo747q1evtpkzZ+b5c6WkpLhapGDavHlznj8nAAAogH12Av369bPZs2fbxx9/bKeddlp4fpUqVVzH4127dkXV7mg0lpYF63z++edR2wtGawXrZFSsWDE3AQAA/8W0ZicUCrmg88Ybb9jChQutdu3aUcubNm1qRYoUsQULFoTnaWi6hpq3atXK3dftqlWrbPv27eF1NLIrKSnJGjRokI97AwAA4lFirJuuNNLqrbfecufaCfrYqB9NiRIl3G3v3r1t0KBBrtOyAkz//v1dwNFILNFQdYWanj172vjx4902hg4d6rZN7Q0AAIhp2Pn73//ubi+++OKo+RpefvPNN7v/T5w40QoXLuxOJqhRVBpp9dRTT4XXTUhIcE1gffr0cSGoVKlS1qtXLxs1alQ+7w0AAIhHibFuxjqa4sWL2+TJk92UlZo1a9qcOXNyuXQAAMAHcTMaCwAAIC8QdgAAgNcIOwAAwGuEHQAA4DXCDgAA8BphBwAAeI2wAwAAvEbYAQAAXiPsAAAArxF2AACA1wg7AADAa4QdAADgNcIOAADwGmEHAAB4jbADAAC8RtgBAABeI+wAAACvEXYAAIDXCDsAAMBrhB0AAOA1wg4AAPAaYQcAAHiNsAMAALxG2AEAAF4j7AAAAK8RdgAAgNcIOwAAwGuEHQAA4DXCDgAA8BphBwAAeI2wAwAAvEbYAQAAXiPsAAAArxF2AACA1wg7AADAa4QdAADgNcIOAADwGmEHAAB4jbADAAC8RtgBAABeI+wAAACvEXYAAIDXCDsAAMBrhB0AAOA1wg4AAPAaYQcAAHiNsAMAALxG2AEAAF4j7AAAAK8RdgAAgNcIOwAAwGuEHQAA4DXCDgAA8BphBwAAeI2wAwAAvEbYAQAAXiPsAAAArxF2AACA1wg7AADAazENOx9//LFdccUVVq1aNStUqJC9+eabUctDoZANGzbMqlataiVKlLD27dvb119/HbXOzp07rUePHpaUlGTlypWz3r172969e/N5TwAAQLyKadj59ddfrXHjxjZ58uRMl48fP94ef/xxmzJlii1dutRKlSplnTp1svT09PA6Cjpr1qyxefPm2ezZs12AuuOOO/JxLwAAQDxLjOWTX3rppW7KjGp1HnvsMRs6dKh16dLFzXv++ectOTnZ1QBdd911tm7dOps7d64tW7bMmjVr5tZ54okn7LLLLrNHHnnE1RgBAICCLW777Hz77be2bds213QVKFu2rLVo0cIWL17s7utWTVdB0BGtX7hwYVcTlJV9+/ZZWlpa1AQAAPwUt2FHQUdUkxNJ94Nluq1cuXLU8sTERKtQoUJ4ncyMHTvWBadgql69ep7sAwAAiL24DTt5KSUlxXbv3h2eNm/eHOsiAQCAghZ2qlSp4m5TU1Oj5ut+sEy327dvj1p+8OBBN0IrWCczxYoVc6O3IicAAOCnuA07tWvXdoFlwYIF4XnqW6O+OK1atXL3dbtr1y5bvnx5eJ2FCxfa4cOHXd8eAACAmI7G0vlwNm7cGNUpecWKFa7PTY0aNeyee+6xMWPGWJ06dVz4efDBB90Iq65du7r169evb5dccondfvvtbnj6gQMHrF+/fm6kFiOxAABAzMPOF198YW3atAnfHzRokLvt1auXTZs2ze677z53Lh6dN0c1OOeff74bal68ePHwY1566SUXcNq1a+dGYXXv3t2dmwcAACDmYefiiy9259PJis6qPGrUKDdlRbVAM2bMyKMSAgCAk13c9tkBAADIDYQdAADgNcIOAADwGmEHAAB4jbADAAC8RtgBAABeI+wAAACvEXYAAIDXCDsAAMBrhB0AAOA1wg4AAPAaYQcAAHiNsAMAALxG2AEAAF4j7AAAAK8RdgAAgNcIOwAAwGuEHQAA4DXCDgAA8BphBwAAeI2wAwAAvEbYAQAAXiPsAAAArxF2AACA1wg7AADAa4QdAADgNcIOAADwGmEHAAB4jbADAAC8RtgBAABeI+wAAACvEXYAAIDXCDsAAMBrhB0AAOA1wg4AAPAaYQcAAHiNsAMAALxG2AEAAF4j7AAAAK8RdgAAgNcIOwAAwGuEHQAA4DXCDgAA8BphBwAAeI2wAwAAvEbYAQAAXiPsAAAArxF2AACA1wg7AADAa4QdAADgNcIOAADwGmEHAAB4jbADAAC8RtgBAABeI+wAAACvEXYAAIDXCDsAAMBrhB0AAOA1wg4AAPCaN2Fn8uTJVqtWLStevLi1aNHCPv/881gXCQAAxAEvws4rr7xigwYNsuHDh9uXX35pjRs3tk6dOtn27dtjXTQAABBjXoSdCRMm2O2332633HKLNWjQwKZMmWIlS5a05557LtZFAwAAMXbSh539+/fb8uXLrX379uF5hQsXdvcXL14c07IBAIDYS7ST3E8//WSHDh2y5OTkqPm6v379+kwfs2/fPjcFdu/e7W7T0tKsoElLT491EZCPChXA13hBlp7G+7sgSUsoeO/vtP/7TAuFQn6HneMxduxYGzly5BHzq1evHpPyAPlm3LhYlwBAHrnf7reCas+ePVa2bFl/w84pp5xiCQkJlpqaGjVf96tUqZLpY1JSUlyH5sDhw4dt586dVrFiRStUqFCelxmx/yWgYLt582ZLSkqKdXEA5CLe3wVLKBRyQadatWrZrnfSh52iRYta06ZNbcGCBda1a9dweNH9fv36ZfqYYsWKuSlSuXLl8qW8iB/6IOTDEPAT7++Co2w2NTrehB1RLU2vXr2sWbNm9sc//tEee+wx+/XXX93oLAAAULB5EXauvfZa27Fjhw0bNsy2bdtmTZo0sblz5x7RaRkAABQ8XoQdUZNVVs1WQCQ1YeoElBmbMgGc/Hh/IzOFQkcbrwUAAHASO+lPKggAAJAdwg4AAPAaYQcAAHiNsIO4oJM5vvnmm1ku/+6779w6K1assHhw8cUX2z333BO+X6tWLXfKg5zuD4BjF/m+yqvPBN67fvJmNBbiz80332zTp093/09MTLQKFSpYo0aN7Prrr3fLdMHWwNatW618+fIWayrXrl27jvnDbtmyZVaqVKk8KxdQUGT3HoyXzwmcfKjZQZ665JJL3AeUfoW9++671qZNGxswYIBdfvnldvDgwfB6urTHyTxUtFKlSlayZMlYFwPw2sn+OYHYIewgT+mDSR9Qp556qv3hD3+wv/zlL/bWW2+54DNt2rQsq44///xzO/fcc6148eLuzNj/+c9/jvpcakp6+OGH7dZbb7UyZcpYjRo17JlnnolaZ9WqVda2bVsrUaKEuxbaHXfcYXv37nXLRowY4WqiVD6VR9OHH36Yo/3M2IyVkc77UbVqVfvqq6/c/U8//dQuuOACVw5dx+fuu+92Z/0GcHxNTIcOHXLv/Xr16tmmTZvcPL2X9bmjz5HTTz/dXQA68kfW119/bRdeeKFb3qBBA5s3b16+7QvyF2EH+U5ho3Hjxvb6669nulzhQzU/+vBZvny5CyH33ntvjrb96KOPhsPRXXfdZX369LENGza4ZQoTnTp1ctXganaaNWuWzZ8/P3wySj3HNddcE66N0tS6desT2ledxqp///72/PPP2yeffOKa8b755hv3HN27d3fh55VXXnHhh5NiAsdn3759dvXVV7v+O3qf6YeObm+66SZXk7x27Vp7+umn3Q+shx56KHwNxW7durnrKy5dutSmTJliQ4YMifWuII8QdhAT+vWlpq3MzJgxw30QPfvss3b22We74DN48OAcbfeyyy5zIefMM890H1ynnHKKffDBB+Htpqenu+BxzjnnuND15JNP2gsvvGCpqalWunRpV9MS1EZp0gfh8dIvyBtvvNFdlFZhRmWSsWPHWo8ePVwH5zp16rhA9fjjj7tyqXwAck4/jjp37uwuGaT3upqURbU4999/v7tuomp1OnToYKNHj3ahR/RDZ/369e59px9fquFRzTD8RAdlxIRqPFQlnZl169a5GhBVLQdatWqVo+3qcQFtX4Fl+/bt4e3qQy2yI/F5553ngpVqf3L7WmoDBw50wWnJkiUudAVWrlzpanReeumlqOOhcnz77bdWv379XC0H4DMNeDjttNNs4cKF7sdK5Pvss88+C9fkBE1d+kHx22+/uc8DNSFXq1btmD9ncPIh7CAm9EFTu3btXN9ukSJFou4r8ChExIJ+Sb788sv23nvvuZqcyF+id955p+unk5Gq3wHknGpzX3zxRVu8eLGrrY18n6l2R01VGUX+kELBQNhBvtMvMHUUVs1HZlSzoaYl/QILPpRUO3KitF212avvTlC7o19+GgJft25dd1/NVvr1lxuuvPJKu+KKK+yGG26whIQEu+6669x8dZhUH4KgWQvA8VO/PDVL6/32zjvv2EUXXRR+n6nGNqv3mT4PNm/e7PrmafBAbn3OID7RZwd53nFw27Zt9uOPP9qXX37p2sS7dOni+uGo82BmFA5UI3P77be7UDBnzhx75JFHTrgsql1ReFIb/urVq137vjoP9+zZM9yEpVFVamLSh+RPP/1kBw4cOKHn/NOf/uSC2y233GKvvfaam6e+RIsWLXIdktWhUiNCNGqEDsrA/9q9e7d7b0ROCiZZ0ft4zJgx7nNF/eNk2LBhrj+OanfWrFnjapNnzpxpQ4cOdcvbt29vZ511lvs8UJOXOjQ/8MAD+baPyF/U7CBPzZ071/1q0kkFNQpKfWbUGVcfMJEnFYykjsJvv/22/dd//Zcbfq5RWX/961/d6KUTofPgqElJozOaN2/u7mubEyZMCK+jgKXh5hrRpWpwBSKdLflEXHXVVa4pTaFK+6xq9Y8++sh9sGr4ufrrnHHGGXbttdee0PMAvtB7UO/9SL179872Merwr/eZmrX0uaORl7Nnz7ZRo0a5zw81cWtgxG233ebW13vxjTfecNv94x//6H7o6LNJIyXhn0IhfdICAAB4imYsAADgNcIOAADwGmEHAAB4jbADAAC8RtgBAABeI+wAAACvEXYAAIDXCDsAYn4COZ0xe9euXVZQ6LIl5cqVO+Ht6Li9+eabuVImwGeEHQC2Y8cOd40hXYhUV2rX1eJ1BlpdOyw36WzUOtNtpNatW7vrE5UtW9Zi7eabb7auXbvm2noA4gOXiwDgLpuxf/9+mz59up1++umWmppqCxYssJ9//jnPn1sXX1W4AoC8Qs0OUMCp+UgXQdT1g9q0aWM1a9Z01wpKSUlxV5KOXE/XFapUqZIlJSVZ27Zt3QUUAyNGjLAmTZq4C5/qOkOqqdGV3vfs2ROuDdE1wSZNmuSaXzR99913RzRjBU08uq6Rrkava5jp+mK//fabC2Patq6zdvfdd0ddoV4Xnb333nvt1FNPdVe1b9Gihdt2INiuro+mK17rGmy6DpJqlYLya/u6KGtQvsjHHwtdb61hw4auHNWrV7e77rrLXWstIzVB1alTx12gVjVpGS92qbLo6t1arhCqi1oePHjwuMoEFGSEHaCA05e+Jn3xKjBk5eqrr7bt27fbu+++a8uXL3dfwu3atbOdO3eG1/nmm2/cdhRUNCncjBs3zi1TyGnVqpW72KoChiYFgcwo2OiijLpKtS7qqNChK8jPmTPHTQpUTz/9dPhK8qKrxi9evNg9RleuV3kVZnRV+cjtPvLII+7xH3/8sW3atMkFJNHtNddcEw5AmtTEdjx0kUmVX1fbVoBauHCh3XfffUfs40MPPeSuzK3mQoU9hcOAAuhNN93kLly7du1at78KbHoMgGOkC4ECKNhee+21UPny5UPFixcPtW7dOpSSkhJauXJlePknn3wSSkpKCqWnp0c97owzzgg9/fTT7v/Dhw8PlSxZMpSWlhZePnjw4FCLFi3C9y+66KLQgAEDorbxwQcf6GLEoV9++cXdnzp1qru/cePG8Dp33nmn2/aePXvC8zp16uTmy/fffx9KSEgI/fjjj1HbbteunduXrLY7efLkUHJycvh+r169Ql26dDnq8crpeoFZs2aFKlasGL4flGXJkiXheevWrXPzli5dGi77ww8/HLWdF154IVS1atXwfa3/xhtv5LgcQEFFnx0Ars9O586dXW3CkiVLXO3N+PHj7Z///KdrflJzlZphKlasGPW433//3dXmBNTEVKZMmfD9qlWrutqgY6WmqzPOOCN8Pzk52W1bNVCR84Jtr1q1yjVpnXXWWVHbUU1VZJkzbvd4y3c08+fPt7Fjx9r69estLS3NNT2lp6e72hyVQRITE6158+bhx9SrV881s61bt841I+qYq8YnsiZH+5hxOwCOjrADwFG/kA4dOrjpwQcfdP1zhg8f7sKOgo6CQWZ9WCKHUBcpUiRqmfq9HD58+JjLktl2stu2ypeQkOCa13QbKTIgZbaN/60gyT3qh3T55Ze70W0KKhUqVLBPP/3Uevfu7TqB5zSkaJ/UR6dbt26Z/q0A5BxhB0CmGjRoED6Hi/rnbNu2zdVGqIblREZeRXYqzi3nnnuu265qaS644IKYlk+BSyHs0UcfdX135NVXXz1iPdX2fPHFF64WRzZs2OD67ajzdHDMNe/MM888ofIAIOwABZ6Gl6sz76233mqNGjVyzVD6ElYzVpcuXdw67du3d52LdW4ZzVdz0ZYtW+ydd95xHYebNWuWo+dSUFq6dKmr/VCNi2o9coPK06NHD9ehVyFD4UfnDtLwee2TmuhyWj6N1lLIUPOXRpRlrA0K7N6921asWBE1T49RODlw4IA98cQTdsUVV7imqClTphzxeG23f//+riOzQqQ6WLds2TIcfoYNG+ZqiHTuI41GU3BS09bq1attzJgxx3WcgIKK0VhAAafQoWHaEydOtAsvvNDOOecc14ylUVNPPvlkuLlHo6C0/JZbbnHhQiOHvv/+e9d3Jqc04knNTKo10hB2jYbKLVOnTnVh589//rMbsq5gtmzZMhcWckr7rMcqvKl82Z1UUU16ClWRk5qdGjdu7Iaeayi/juVLL73k+u9kpOasIUOG2A033GDnnXee+zu88sor4eUaiq4Rbe+//77r26MgpL+RTg0A4NgUUi/lY3wMAADASYOaHQAA4DXCDgAA8BphBwAAeI2wAwAAvEbYAQAAXiPsAAAArxF2AACA1wg7AADAa4QdAADgNcIOAADwGmEHAAB4jbADAADMZ/8PcGT0v6J7VKYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt  # For plotting\n",
    "\n",
    "#Get the values count \n",
    "counts = df['Liked'].value_counts()\n",
    "\n",
    "#Create a bar plot\n",
    "ax = counts.plot(kind='bar', color=['lightcoral', 'lightgreen'])\n",
    "ax.set_title('Distribution of Sentiment Labels')\n",
    "ax.set_xlabel('Sentiment Label')\n",
    "ax.set_ylabel('Count')\n",
    "plt.xticks(ticks=[0, 1], labels=['Did not like', 'Liked'], rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd11a047",
   "metadata": {},
   "source": [
    "To find frequent Keywords in Positive vs. Negative Reviews: Do certain words signal dissatisfaction (e.g., \"cold,\" \"slow,\" \"expensive\") while others indicate satisfaction (e.g., \"delicious,\" \"friendly,\" \"cozy\")?\n",
    "\n",
    "For that I need first of all \n",
    "1. Do a text preprocessing \n",
    "2. Separate Text by Sentiment Category\n",
    "3. Count Word Frequencies\n",
    "4. Beyond Simple Frequency - Using N-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5824ca",
   "metadata": {},
   "source": [
    "## 3.1 Text Preprocessing  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "49117d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Review  \\\n",
      "0                             Wow... Loved this place.   \n",
      "1                                   Crust is not good.   \n",
      "2            Not tasty and the texture was just nasty.   \n",
      "3    Stopped by during the late May bank holiday of...   \n",
      "4    The selection on the menu was great and so wer...   \n",
      "..                                                 ...   \n",
      "995  I think food should have flavor and texture an...   \n",
      "996                           Appetite instantly gone.   \n",
      "997  Overall I was not impressed and would not go b...   \n",
      "998  The whole experience was underwhelming, and I ...   \n",
      "999  Then, as if I hadn't wasted enough of my life ...   \n",
      "\n",
      "                                          clean_tokens  \n",
      "0                                  [wow, loved, place]  \n",
      "1                                        [crust, good]  \n",
      "2                              [tasty, texture, nasty]  \n",
      "3    [stopped, late, may, bank, holiday, rick, stev...  \n",
      "4                      [selection, menu, great, price]  \n",
      "..                                                 ...  \n",
      "995            [think, food, flavor, texture, lacking]  \n",
      "996                        [appetite, instantly, gone]  \n",
      "997              [overall, impressed, would, go, back]  \n",
      "998  [whole, experience, underwhelming, think, well...  \n",
      "999  [hadnt, wasted, enough, life, poured, salt, wo...  \n",
      "\n",
      "[1000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    lemmatizer = WordNetLemmatizer() # Reducing words to their base or root form\n",
    "    stop_words = set(stopwords.words('english')) #Eliminating common words like \"the,\" \"is,\" and \"a\" that don't carry much sentiment\n",
    "    text = text.lower() #Converting all words to lowercase to ensure consistency\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove punctuation and numbers\n",
    "    tokens = word_tokenize(text) # : Splitting the text into individual words or \"tokens.\"\n",
    "    filtered_tokens = [\n",
    "        lemmatizer.lemmatize(token) for token in tokens\n",
    "        if token not in stop_words\n",
    "    ]\n",
    "    return filtered_tokens\n",
    "\n",
    "# Apply the preprocessing\n",
    "df['clean_tokens'] = df['Review'].apply(preprocess_text)\n",
    "print(df[['Review', 'clean_tokens']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c923558",
   "metadata": {},
   "source": [
    "### 3.2 Separate Text by Sentiment Category\n",
    "\n",
    "To find frequent words for each sentiment, I first need to group your data by its sentiment label in this case the Like column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "71fb67d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the DataFrame into positive and negative sentiments\n",
    "positive_df = df[df['Liked'] == 1]\n",
    "negative_df = df[df['Liked'] == 0]\n",
    "\n",
    "# Flatten the list of tokens for each sentiment\n",
    "positive_words = [token for tokens in positive_df['clean_tokens'] for token in tokens]\n",
    "negative_words = [token for tokens in negative_df['clean_tokens'] for token in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f386bde5",
   "metadata": {},
   "source": [
    "### 3.3 Count Word Frequencies\n",
    "\n",
    "Using collections.Counter to find the most common words for each category.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a673bb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Positive Words:\n",
      "[('good', 73), ('great', 70), ('place', 60), ('food', 60), ('service', 46), ('time', 26), ('friendly', 23), ('delicious', 23), ('back', 23), ('nice', 22)]\n",
      "\n",
      "Top 10 Negative Words:\n",
      "[('food', 65), ('place', 51), ('back', 38), ('service', 38), ('like', 29), ('time', 29), ('go', 26), ('dont', 25), ('good', 22), ('never', 22)]\n"
     ]
    }
   ],
   "source": [
    "# Count the frequency of words in each sentiment group\n",
    "positive_word_counts = Counter(positive_words)\n",
    "negative_word_counts = Counter(negative_words)\n",
    "\n",
    "# Get the top N most frequent words for each sentiment\n",
    "top_10_positive = positive_word_counts.most_common(10)\n",
    "top_10_negative = negative_word_counts.most_common(10)\n",
    "\n",
    "print(\"\\nTop 10 Positive Words:\")\n",
    "print(top_10_positive)\n",
    "print(\"\\nTop 10 Negative Words:\")\n",
    "print(top_10_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63e1b56",
   "metadata": {},
   "source": [
    "### 3.4 Beyond Simple Frequency - Using N-grams\n",
    "\n",
    "Simple word frequency (unigrams) can be misleading, especially with negations. For example, \"not good\" should be treated as a negative phrase, but a simple unigram count would count \"good\" as a positive word.\n",
    "\n",
    "Using N-grams (sequences of N words) helps solve this. You can find frequent pairs of words (bigrams) or triples (trigrams) that might be more indicative of sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0ed1df6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Positive Bigrams:\n",
      "[(('great', 'food'), 8), (('food', 'good'), 7), (('great', 'service'), 6), (('go', 'back'), 6), (('really', 'good'), 6), (('good', 'food'), 6), (('food', 'great'), 6), (('great', 'place'), 6), (('food', 'delicious'), 5), (('first', 'time'), 5)]\n",
      "\n",
      "Top 10 Negative Bigrams:\n",
      "[(('go', 'back'), 12), (('going', 'back'), 7), (('dont', 'think'), 5), (('wont', 'back'), 5), (('ever', 'go'), 5), (('anytime', 'soon'), 5), (('bad', 'food'), 4), (('never', 'ever'), 4), (('waste', 'time'), 4), (('zero', 'star'), 4)]\n"
     ]
    }
   ],
   "source": [
    "# Generate bigrams for each sentiment\n",
    "positive_bigrams = list(bigrams(positive_words))\n",
    "negative_bigrams = list(bigrams(negative_words))\n",
    "\n",
    "# Count the frequency of bigrams\n",
    "positive_bigram_counts = Counter(positive_bigrams)\n",
    "negative_bigram_counts = Counter(negative_bigrams)\n",
    "\n",
    "# Get the top 10 most frequent bigrams for each sentiment\n",
    "top_10_positive_bigrams = positive_bigram_counts.most_common(10)\n",
    "top_10_negative_bigrams = negative_bigram_counts.most_common(10)\n",
    "\n",
    "print(\"\\nTop 10 Positive Bigrams:\")\n",
    "print(top_10_positive_bigrams)\n",
    "print(\"\\nTop 10 Negative Bigrams:\")\n",
    "print(top_10_negative_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5bd5f2f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "      <th>clean_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "      <td>[wow, loved, place]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "      <td>[crust, good]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "      <td>[tasty, texture, nasty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "      <td>[stopped, late, may, bank, holiday, rick, stev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>[selection, menu, great, price]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked  \\\n",
       "0                           Wow... Loved this place.      1   \n",
       "1                                 Crust is not good.      0   \n",
       "2          Not tasty and the texture was just nasty.      0   \n",
       "3  Stopped by during the late May bank holiday of...      1   \n",
       "4  The selection on the menu was great and so wer...      1   \n",
       "\n",
       "                                        clean_tokens  \n",
       "0                                [wow, loved, place]  \n",
       "1                                      [crust, good]  \n",
       "2                            [tasty, texture, nasty]  \n",
       "3  [stopped, late, may, bank, holiday, rick, stev...  \n",
       "4                    [selection, menu, great, price]  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7fe0e2",
   "metadata": {},
   "source": [
    "## 4. Shuffle the Data and Split in train and Test \n",
    "\n",
    "The main reason is to ensure that my training and test data sets are representative of the full data set.\n",
    "\n",
    "Randomly shuffling the data ensures that the proportion of positive and negative reviews is roughly the same in both sets (training and testing), allowing the model to learn from all types of data and evaluate itself fairly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4b6bed03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size (X_train): (800,)\n",
      "Test set size (X_test): (200,)\n",
      "Training target size (y_train): (800,)\n",
      "Test target size (y_test): (200,)\n"
     ]
    }
   ],
   "source": [
    "# 1. Import the necessary library\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 2. Prepare your data\n",
    "# 'X' will be your features (the text or tokens column)\n",
    "# 'y' will be your target variable (the 'Liked' sentiment column)\n",
    "X = df['clean_tokens'].apply(lambda tokens: ' '.join(tokens))\n",
    "y = df['Liked']\n",
    "\n",
    "# 3. Split the data into training and testing sets.\n",
    "# `train_test_split` automatically shuffles the data for you,\n",
    "# so you don't need a separate shuffling step.\n",
    "# `test_size` specifies the proportion for the test set (e.g., 20%)\n",
    "# `random_state` ensures the split is the same every time you run the code.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the size of the new datasets\n",
    "print(\"Training set size (X_train):\", X_train.shape)\n",
    "print(\"Test set size (X_test):\", X_test.shape)\n",
    "print(\"Training target size (y_train):\", y_train.shape)\n",
    "print(\"Test target size (y_test):\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a03086",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering\n",
    "\n",
    "Using techniques like TF-IDF, word embeddings, or sentiment lexicons to improve model performance.\n",
    "\n",
    "TF-IDF stands for Term Frequency-Inverse Document Frequency \n",
    "\n",
    "The TF-IDF Vectorizer is a widely used tool for this purpose. It transforms sentences into a sparse matrix where each row corresponds to a document (sentence) and each column represents a term (word or token).\n",
    "\n",
    "Here, we’ll use the TfidfVectorizer out of the box with its default configuration. By default, this includes:\n",
    "* Only unigrams (individual terms/tokens) as features.\n",
    "* A maximum document frequency of 1.0 (no terms are excluded based on frequency).\n",
    "* Normalization applied to the resulting feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "664bed2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TF-IDF matrix (Training): (800, 5020)\n",
      "Shape of TF-IDF matrix (Testing): (200, 5020)\n"
     ]
    }
   ],
   "source": [
    "# Import TF-IDF Vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Define the vectorizer\n",
    "# I add the parameter `ngram_range=(1, 2)` to include both unigrams (single words) and bigrams (two-word combinations).\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "\n",
    "# Fit the vectorizer on the TRAINING data and transform it.\n",
    "# This learns the vocabulary and feature weights from the training set.\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the TEST data using the SAME vectorizer.\n",
    "# We use only `transform` here to apply the vocabulary and weights learned from the training data.\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Check the shapes to confirm the transformation was successful\n",
    "print(\"Shape of TF-IDF matrix (Training):\", X_train_tfidf.shape)\n",
    "print(\"Shape of TF-IDF matrix (Testing):\", X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa95d31",
   "metadata": {},
   "source": [
    "## 6. Training The Classifier: Model Selection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb674ce4",
   "metadata": {},
   "source": [
    "### Comparative table between logistic regression vs. decision tree classifier\n",
    "\n",
    "Logistic Regression is a linear model. It finds a straight line (or hyperplane) to separate the data. It's often a great baseline model, is fast to train, and its results are easy to interpret.\n",
    "\n",
    "Decision Tree is a non-linear model. It makes a series of if-then-else decisions to classify data. It can capture more complex relationships but is prone to overfitting, meaning it might perform well on your training data but poorly on unseen test data. The max_depth parameter helps control this by limiting the complexity of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b2d17818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Logistic Regression Model ---\n",
      "Logistic Regression Accuracy: 0.79\n",
      "\n",
      "Logistic Regression Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79        96\n",
      "           1       0.82      0.76      0.79       104\n",
      "\n",
      "    accuracy                           0.79       200\n",
      "   macro avg       0.79      0.79      0.79       200\n",
      "weighted avg       0.79      0.79      0.79       200\n",
      "\n",
      "\n",
      "--- Training Decision Tree Model ---\n",
      "Decision Tree Accuracy: 0.645\n",
      "\n",
      "Decision Tree Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.93      0.71        96\n",
      "           1       0.85      0.38      0.53       104\n",
      "\n",
      "    accuracy                           0.65       200\n",
      "   macro avg       0.72      0.66      0.62       200\n",
      "weighted avg       0.72      0.65      0.62       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model 1: Logistic Regression\n",
    "print(\"\\n--- Training Logistic Regression Model ---\")\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "lr_predictions = lr_model.predict(X_test_tfidf)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, lr_predictions))\n",
    "print(\"\\nLogistic Regression Classification Report:\\n\", classification_report(y_test, lr_predictions))\n",
    "\n",
    "# Model 2: Decision Tree\n",
    "print(\"\\n--- Training Decision Tree Model ---\")\n",
    "dt_model = DecisionTreeClassifier(random_state=42, max_depth=10)\n",
    "dt_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "dt_predictions = dt_model.predict(X_test_tfidf)\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, dt_predictions))\n",
    "print(\"\\nDecision Tree Classification Report:\\n\", classification_report(y_test, dt_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b057646c",
   "metadata": {},
   "source": [
    "### How to Interpret the Results: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04a5690",
   "metadata": {},
   "source": [
    "| Metric | Logistic Regression | Decision Tree |\n",
    "| :--- | :--- | :--- |\n",
    "| **Accuracy** | 0.775 | 0.635 |\n",
    "| **Precision (Class 0)** | 0.74 | 0.58 |\n",
    "| **Recall (Class 0)** | 0.82 | 0.92 |\n",
    "| **F1-Score (Class 0)** | 0.78 | 0.71 |\n",
    "| **Precision (Class 1)** | 0.82 | 0.83 |\n",
    "| **Recall (Class 1)** | 0.73 | 0.38 |\n",
    "| **F1-Score (Class 1)** | 0.77 | 0.52 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f2b5f6",
   "metadata": {},
   "source": [
    "**Conclusion:** The Logistic Regression is the model with the best overall performance for this dataset, showing higher accuracy and a better balance between the metrics of both classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314d9b73",
   "metadata": {},
   "source": [
    "After selecting a model like Logistic Regression, the next professional step is to improve its performance and get a more reliable evaluation. \n",
    "\n",
    "The best way to do this is by combining two techniques:\n",
    "\n",
    "* k-fold cross-validation: This involves splitting the data into multiple folds and training the model on different combinations of these folds. It gives a more stable and trustworthy performance score than a single train-test split.\n",
    "\n",
    "* Hyperparameter tuning: This is the process of finding the optimal settings (hyperparameters) for your model, such as the C value in Logistic Regression, to maximize its performance.\n",
    "\n",
    "The most effective and professional practice is to use a tool like GridSearchCV that performs both of these steps automatically, ensuring you find the best possible model settings and a reliable performance score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67bb1f7",
   "metadata": {},
   "source": [
    "## 7. Hyperparameter Tuning with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "79269bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Hyperparameter Tuning for Logistic Regression ---\n",
      "Best parameters found:  {'C': 10.0}\n",
      "Best cross-validation score: 0.79\n",
      "\n",
      "--- Evaluation of the Best Logistic Regression Model ---\n",
      "Accuracy of the best model: 0.795\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.82      0.79        96\n",
      "           1       0.82      0.77      0.80       104\n",
      "\n",
      "    accuracy                           0.80       200\n",
      "   macro avg       0.80      0.80      0.79       200\n",
      "weighted avg       0.80      0.80      0.80       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for cross-validation and hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# --- Hyperparameter Tuning for Logistic Regression ---\n",
    "# Cross-validation is used to find the best 'C' parameter\n",
    "# (regularization strength) for the model.\n",
    "\n",
    "print(\"\\n--- Hyperparameter Tuning for Logistic Regression ---\")\n",
    "\n",
    "# Define the parameters you want to test.\n",
    "# 'C' is the regularization hyperparameter. Smaller values mean\n",
    "# stronger regularization.\n",
    "param_grid = {'C': [0.1, 1.0, 10.0, 100.0]}\n",
    "\n",
    "# Create the GridSearchCV object.\n",
    "# - estimator: the model to be tuned (LogisticRegression).\n",
    "# - param_grid: the dictionary of parameters to test.\n",
    "# - cv: the number of folds for cross-validation.\n",
    "grid_search = GridSearchCV(LogisticRegression(random_state=42), param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the GridSearchCV to your training data.\n",
    "# This trains the model 5 times for each 'C' value.\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Display the best parameters found\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "# --- Evaluation of the Best Model ---\n",
    "# Use the best model found to make predictions on the test set\n",
    "best_lr_model = grid_search.best_estimator_\n",
    "best_lr_predictions = best_lr_model.predict(X_test_tfidf)\n",
    "\n",
    "# Display the classification report of the best model\n",
    "print(\"\\n--- Evaluation of the Best Logistic Regression Model ---\")\n",
    "print(\"Accuracy of the best model: {:.3f}\".format(accuracy_score(y_test, best_lr_predictions)))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, best_lr_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77b4964",
   "metadata": {},
   "source": [
    "**LinearSVC** is a fast and efficient linear classifier based on Support Vector Machines (SVM). \n",
    "\n",
    "It is particularly well-suited for high-dimensional datasets like those created from text data using TF-IDF. \n",
    "It finds an optimal boundary to separate classes and, like Logistic Regression, uses a C parameter to manage overfitting. \n",
    "By tuning and comparing it against your Logistic Regression model, you can determine which one is the best linear classifier for your specific sentiment analysis task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a004a942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Hyperparameter Tuning for LinearSVC ---\n",
      "Best parameters found (LinearSVC):  {'C': 1.0}\n",
      "Best cross-validation score (LinearSVC): 0.79\n",
      "\n",
      "--- Evaluation of the Best LinearSVC Model ---\n",
      "Accuracy of the best model: 0.795\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.81      0.79        96\n",
      "           1       0.82      0.78      0.80       104\n",
      "\n",
      "    accuracy                           0.80       200\n",
      "   macro avg       0.80      0.80      0.79       200\n",
      "weighted avg       0.80      0.80      0.80       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dianaterraza/Desktop/nlp_project/cat/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/dianaterraza/Desktop/nlp_project/cat/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/dianaterraza/Desktop/nlp_project/cat/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/dianaterraza/Desktop/nlp_project/cat/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/dianaterraza/Desktop/nlp_project/cat/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# --- Hyperparameter Tuning for LinearSVC ---\n",
    "# Similar to Logistic Regression, we'll tune the 'C' parameter for LinearSVC\n",
    "print(\"\\n--- Hyperparameter Tuning for LinearSVC ---\")\n",
    "\n",
    "# Define the parameters to test for LinearSVC.\n",
    "param_grid_svc = {'C': [0.1, 1.0, 10.0, 100.0]}\n",
    "\n",
    "# Create the GridSearchCV object for LinearSVC\n",
    "grid_search_svc = GridSearchCV(LinearSVC(random_state=42), param_grid_svc, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the GridSearchCV to the training data\n",
    "grid_search_svc.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Display the best parameters and score\n",
    "print(\"Best parameters found (LinearSVC): \", grid_search_svc.best_params_)\n",
    "print(\"Best cross-validation score (LinearSVC): {:.2f}\".format(grid_search_svc.best_score_))\n",
    "\n",
    "# --- Evaluation of the Best LinearSVC Model ---\n",
    "best_svc_model = grid_search_svc.best_estimator_\n",
    "best_svc_predictions = best_svc_model.predict(X_test_tfidf)\n",
    "\n",
    "print(\"\\n--- Evaluation of the Best LinearSVC Model ---\")\n",
    "print(\"Accuracy of the best model: {:.3f}\".format(accuracy_score(y_test, best_svc_predictions)))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, best_svc_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8522e1c4",
   "metadata": {},
   "source": [
    "### 8. Conclusion\n",
    "\n",
    "Both the Logistic Regression and LinearSVC models, after being optimized with GridSearchCV, show nearly identical performance on your dataset.\n",
    "\n",
    "Both models achieved a final accuracy of 0.795.\n",
    "\n",
    "The F1-Score, Precision, and Recall metrics are also extremely close for both models.\n",
    "\n",
    "In this case, either model would be an excellent choice. Since they perform similarly, the choice often comes down to other factors like training time or ease of implementation, but for this problem, the difference is negligible.\n",
    "\n",
    "You can select either the hyperparameter-tuned Logistic Regression model or the LinearSVC model for your final sentiment classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cat (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
